```python
#Import package
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import scipy.stats as stats
from sklearn.preprocessing import StandardScaler, PowerTransformer, OneHotEncoder
from sklearn import model_selection
from xgboost import XGBClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import ExtraTreeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import ShuffleSplit
from sklearn.model_selection import cross_validate
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import RidgeClassifier
from sklearn.linear_model import SGDClassifier
from sklearn.ensemble import BaggingClassifier,VotingClassifier,AdaBoostClassifier,GradientBoostingClassifier

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import cross_val_score
from itertools import combinations
from scipy.stats.stats import pearsonr
pd.options.display.max_columns = None
pd.options.display.max_rows = None
```


```python
#读取文件
file1 = 'train.csv'
file2 = 'test.csv'
train = pd.read_csv(file1)
test = pd.read_csv(file2)
```


```python
target = 'Attrition'
y_train = train[target]
y_train = np.where(y_train=='Yes',1,0)
```


```python
#查看变量
train.columns
```




    Index(['user_id', 'Age', 'Attrition', 'BusinessTravel', 'DailyRate',
           'Department', 'DistanceFromHome', 'Education', 'EducationField',
           'EmployeeCount', 'EmployeeNumber', 'EnvironmentSatisfaction', 'Gender',
           'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobRole',
           'JobSatisfaction', 'MaritalStatus', 'MonthlyIncome', 'MonthlyRate',
           'NumCompaniesWorked', 'Over18', 'OverTime', 'PercentSalaryHike',
           'PerformanceRating', 'RelationshipSatisfaction', 'StandardHours',
           'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear',
           'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole',
           'YearsSinceLastPromotion', 'YearsWithCurrManager'],
          dtype='object')




```python
features = [x for x in train.columns if x not in ['Attrition','Over18','user_id','EmployeeCount']]
```


```python
train_ex = train[features]
test_ex = test[features]
```

### Feature Dealing


```python
#String label to Value label only
def extract_features(df):
    
    # BusinessTravel
    businesstravel_dict = {'Non-Travel':0, 'Travel_Rarely':1, 'Travel_Frequently':2}
    df['BusinessTravel'] = df['BusinessTravel'].map(lambda x: businesstravel_dict[x])
    # Department
    department_dict = {'Sales':0, 'Research & Development':1, 'Human Resources':2}
    df['Department'] = df['Department'].map(lambda x: department_dict[x])
    # EducationField
    educationfield_dict = {'Life Sciences':0, 'Medical':1, 'Marketing':2, 'Technical Degree':3, 'Human Resources':4, 'Other':5}
    df['EducationField'] = df['EducationField'].map(lambda x: educationfield_dict[x])
    # Gender
    gender_dict = {'Male':0, 'Female': 1}
    df['Gender'] = df['Gender'].map(lambda x: gender_dict[x])
    # JobRole
    jobrole_dict = {'Sales Executive':0, 
                    'Research Scientist':1, 
                    'Laboratory Technician':2, 
                    'Manufacturing Director':3, 
                    'Healthcare Representative':4,
                    'Manager':5, 
                    'Sales Representative':6,
                    'Research Director':7,
                    'Human Resources':8
                   }
    df['JobRole'] = df['JobRole'].map(lambda x: jobrole_dict[x])
    # MaritalStatus
    maritalstatus_dict = {'Single':0, 'Married':1, 'Divorced':2}
    df['MaritalStatus'] = df['MaritalStatus'].map(lambda x: maritalstatus_dict[x])
    # OverTime
    overtime_dict = {'Yes':0, 'No':1}
    df['OverTime'] = df['OverTime'].map(lambda x: overtime_dict[x])
    return df
```


```python
X_train = extract_features(train_ex)
X_test = extract_features(test_ex)
```

    /opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      
    /opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      if __name__ == '__main__':
    /opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      if sys.path[0] == '':
    /opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      from ipykernel import kernelapp as app
    /opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
    /opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
    /opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy



```python
seed = 1075
np.random.seed(seed)
# Create classifiers
xgb = XGBClassifier()
dt = DecisionTreeClassifier()
svc =  SVC()
kn = KNeighborsClassifier()
gb = GradientBoostingClassifier()
ridge = RidgeClassifier()
sgd = SGDClassifier()
lr = LogisticRegression()
        
clf_array = [xgb, dt, svc, kn, gb, ridge, sgd]
names = ['XGB Classifier', 'DecisionTree Classifier', 'SVC', 'KNeighbors Classifier','GradientBoosting Classifier','Ridge Classifier','SGD Classifier']

for clf in clf_array:
    vanilla_scores = cross_val_score(clf, X_train, y_train, cv=10, n_jobs=-1)
    bagging_clf = BaggingClassifier(clf,max_samples=0.4, max_features=10, random_state=seed)
    bagging_scores = cross_val_score(bagging_clf, X_train, y_train, cv=10, n_jobs=-1)
    print("Mean of: {1:.3f}, std: (+/-) {2:.3f} ,[{0}]".format(clf.__class__.__name__, 
                                                              vanilla_scores.mean(), vanilla_scores.std()))
    print("Mean of: {1:.3f}, std: (+/-) {2:.3f} ,[Bagging {0}]\n".format(clf.__class__.__name__, 
                                                                        bagging_scores.mean(), bagging_scores.std()))
```

    Mean of: 0.872, std: (+/-) 0.012 ,[XGBClassifier]
    Mean of: 0.847, std: (+/-) 0.008 ,[Bagging XGBClassifier]
    
    Mean of: 0.762, std: (+/-) 0.040 ,[DecisionTreeClassifier]
    Mean of: 0.846, std: (+/-) 0.010 ,[Bagging DecisionTreeClassifier]
    
    Mean of: 0.840, std: (+/-) 0.002 ,[SVC]
    Mean of: 0.840, std: (+/-) 0.002 ,[Bagging SVC]
    
    Mean of: 0.818, std: (+/-) 0.019 ,[KNeighborsClassifier]
    Mean of: 0.840, std: (+/-) 0.002 ,[Bagging KNeighborsClassifier]
    
    Mean of: 0.867, std: (+/-) 0.018 ,[GradientBoostingClassifier]
    Mean of: 0.849, std: (+/-) 0.010 ,[Bagging GradientBoostingClassifier]
    
    Mean of: 0.861, std: (+/-) 0.013 ,[RidgeClassifier]
    Mean of: 0.840, std: (+/-) 0.002 ,[Bagging RidgeClassifier]
    
    Mean of: 0.780, std: (+/-) 0.166 ,[SGDClassifier]
    Mean of: 0.840, std: (+/-) 0.002 ,[Bagging SGDClassifier]
    



```python
# Set up voting
eclf = VotingClassifier(estimators=[('XGB Classifier', xgb), 
                                    ('DecisionTree Classifier', dt), 
                                    ('SVC', svc), 
                                    ('KNeighbors Classifier', kn),
                                    ('GradientBoosting Classifier',gb),
                                    ('Ridge Classifier',ridge),
                                    ('SGD Classifier',sgd)
                                   ], voting='hard')

for clf, label in zip([xgb, dt, svc, kn, gb, ridge, sgd, eclf], ['XGB Classifier', 
                                                                 'DecisionTree Classifier', 
                                                                 'SVC', 
                                                                 'KNeighbors Classifier',
                                                                 'GradientBoosting Classifier',
                                                                 'Ridge Classifier',
                                                                 'SGD Classifier',
                                                                 'Ensemble']):
    scores = cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy')
    print("Mean: {0:.3f}, std: (+/-) {1:.3f} [{2}]".format(scores.mean(), scores.std(), label))
```

    Mean: 0.872, std: (+/-) 0.012 [XGB Classifier]
    Mean: 0.776, std: (+/-) 0.038 [DecisionTree Classifier]


    /opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.
      "avoid this warning.", FutureWarning)
    /opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.
      "avoid this warning.", FutureWarning)
    /opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.
      "avoid this warning.", FutureWarning)
    /opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.
      "avoid this warning.", FutureWarning)
    /opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.
      "avoid this warning.", FutureWarning)
    /opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.
      "avoid this warning.", FutureWarning)
    /opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.
      "avoid this warning.", FutureWarning)
    /opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.
      "avoid this warning.", FutureWarning)
    /opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.
      "avoid this warning.", FutureWarning)
    /opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.
      "avoid this warning.", FutureWarning)


    Mean: 0.840, std: (+/-) 0.002 [SVC]
    Mean: 0.818, std: (+/-) 0.019 [KNeighbors Classifier]
    Mean: 0.867, std: (+/-) 0.018 [GradientBoosting Classifier]
    Mean: 0.861, std: (+/-) 0.013 [Ridge Classifier]
    Mean: 0.838, std: (+/-) 0.008 [SGD Classifier]


    /opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.
      "avoid this warning.", FutureWarning)
    /opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.
      "avoid this warning.", FutureWarning)
    /opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.
      "avoid this warning.", FutureWarning)
    /opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.
      "avoid this warning.", FutureWarning)
    /opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.
      "avoid this warning.", FutureWarning)
    /opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.
      "avoid this warning.", FutureWarning)
    /opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.
      "avoid this warning.", FutureWarning)
    /opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.
      "avoid this warning.", FutureWarning)
    /opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.
      "avoid this warning.", FutureWarning)
    /opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.
      "avoid this warning.", FutureWarning)


    Mean: 0.855, std: (+/-) 0.014 [Ensemble]



```python
from mlxtend.classifier import EnsembleVoteClassifier
# Create boosting classifiers
ada_boost = AdaBoostClassifier()
grad_boost = GradientBoostingClassifier()
xgb_boost = XGBClassifier()

boost_array = [ada_boost, grad_boost, xgb_boost]

eclf = EnsembleVoteClassifier(clfs=[ada_boost, grad_boost, xgb_boost], voting='hard')

labels = ['Ada Boost', 'Grad Boost', 'XG Boost', 'Ensemble']

for clf, label in zip([ada_boost, grad_boost, xgb_boost, eclf], labels):
    scores = cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy')
    print("Mean: {0:.3f}, std: (+/-) {1:.3f} [{2}]".format(scores.mean(), scores.std(), label))
```

    Mean: 0.874, std: (+/-) 0.026 [Ada Boost]
    Mean: 0.869, std: (+/-) 0.017 [Grad Boost]
    Mean: 0.872, std: (+/-) 0.012 [XG Boost]
    Mean: 0.874, std: (+/-) 0.011 [Ensemble]



```python
eclf.fit(X_train,y_train)
y_predict = eclf.predict_proba(X_test)
```


```python
y1_predict = y_predict[:,1]
```


```python
test_id = test['user_id']
submission = pd.DataFrame({"user_id":test_id, "Attrition": y1_predict})
submission.to_csv('submissionV2.csv',index=False)
```


```python

```


